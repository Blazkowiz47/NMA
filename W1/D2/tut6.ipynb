{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#@title Figure Settings\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle\")\n",
    "\n",
    "# @title Plotting Functions\n",
    "\n",
    "\n",
    "def plot_cross_validate_MSE(mse_all):\n",
    "  \"\"\" Plot the MSE values for the K_fold cross validation\n",
    "\n",
    "  Args:\n",
    "    mse_all (ndarray): an array of size (number of splits, max_order + 1)\n",
    "  \"\"\"\n",
    "  plt.figure()\n",
    "  plt.boxplot(mse_all, labels=np.arange(0, max_order + 1))\n",
    "\n",
    "  plt.xlabel('Polynomial Order')\n",
    "  plt.ylabel('Validation MSE')\n",
    "  plt.title(f'Validation MSE over {n_splits} splits of the data')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def plot_AIC(order_list, AIC_list):\n",
    "  \"\"\" Plot the AIC value for fitted polynomials of various orders\n",
    "\n",
    "  Args:\n",
    "    order_list (list): list of fitted polynomial orders\n",
    "    AIC_list (list): list of AIC values corresponding to each polynomial model on order_list\n",
    "  \"\"\"\n",
    "  plt.bar(order_list, AIC_list)\n",
    "  plt.ylabel('AIC')\n",
    "  plt.xlabel('polynomial order')\n",
    "  plt.title('comparing polynomial fits')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "# @title Helper Functions\n",
    "\n",
    "def ordinary_least_squares(x, y):\n",
    "  \"\"\"Ordinary least squares estimator for linear regression.\n",
    "\n",
    "  Args:\n",
    "    x (ndarray): design matrix of shape (n_samples, n_regressors)\n",
    "    y (ndarray): vector of measurements of shape (n_samples)\n",
    "\n",
    "  Returns:\n",
    "    ndarray: estimated parameter values of shape (n_regressors)\n",
    "  \"\"\"\n",
    "\n",
    "  return np.linalg.inv(x.T @ x) @ x.T @ y\n",
    "\n",
    "\n",
    "def make_design_matrix(x, order):\n",
    "  \"\"\"Create the design matrix of inputs for use in polynomial regression\n",
    "\n",
    "  Args:\n",
    "    x (ndarray): input vector of shape (n_samples)\n",
    "    order (scalar): polynomial regression order\n",
    "\n",
    "  Returns:\n",
    "    ndarray: design matrix for polynomial regression of shape (samples, order+1)\n",
    "  \"\"\"\n",
    "\n",
    "  # Broadcast to shape (n x 1)\n",
    "  if x.ndim == 1:\n",
    "    x = x[:, None]\n",
    "\n",
    "  #if x has more than one feature, we don't want multiple columns of ones so we assign\n",
    "  # x^0 here\n",
    "  design_matrix = np.ones((x.shape[0], 1))\n",
    "\n",
    "  # Loop through rest of degrees and stack columns\n",
    "  for degree in range(1, order + 1):\n",
    "      design_matrix = np.hstack((design_matrix, x**degree))\n",
    "\n",
    "  return design_matrix\n",
    "\n",
    "\n",
    "def solve_poly_reg(x, y, max_order):\n",
    "  \"\"\"Fit a polynomial regression model for each order 0 through max_order.\n",
    "\n",
    "  Args:\n",
    "    x (ndarray): input vector of shape (n_samples)\n",
    "    y (ndarray): vector of measurements of shape (n_samples)\n",
    "    max_order (scalar): max order for polynomial fits\n",
    "\n",
    "  Returns:\n",
    "    dict: fitted weights for each polynomial model (dict key is order)\n",
    "  \"\"\"\n",
    "\n",
    "  # Create a dictionary with polynomial order as keys, and np array of theta\n",
    "  # (weights) as the values\n",
    "  theta_hats = {}\n",
    "\n",
    "  # Loop over polynomial orders from 0 through max_order\n",
    "  for order in range(max_order + 1):\n",
    "\n",
    "    X = make_design_matrix(x, order)\n",
    "    this_theta = ordinary_least_squares(X, y)\n",
    "\n",
    "    theta_hats[order] = this_theta\n",
    "\n",
    "  return theta_hats\n",
    "\n",
    "\n",
    "def evaluate_poly_reg(x, y, theta_hats, max_order):\n",
    "    \"\"\" Evaluates MSE of polynomial regression models on data\n",
    "\n",
    "    Args:\n",
    "      x (ndarray): input vector of shape (n_samples)\n",
    "      y (ndarray): vector of measurements of shape (n_samples)\n",
    "      theta_hat (dict): fitted weights for each polynomial model (dict key is order)\n",
    "      max_order (scalar): max order of polynomial fit\n",
    "\n",
    "    Returns\n",
    "      (ndarray): mean squared error for each order, shape (max_order)\n",
    "    \"\"\"\n",
    "\n",
    "    mse = np.zeros((max_order + 1))\n",
    "    for order in range(0, max_order + 1):\n",
    "      X_design = make_design_matrix(x, order)\n",
    "      y_hat = np.dot(X_design, theta_hats[order])\n",
    "      residuals = y - y_hat\n",
    "      mse[order] = np.mean(residuals ** 2)\n",
    "\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "#@markdown Execute this cell to simulate data and fit polynomial regression models\n",
    "\n",
    "### Generate training data\n",
    "np.random.seed(0)\n",
    "n_train_samples = 50\n",
    "x_train = np.random.uniform(-2, 2.5, n_train_samples)  # sample from a uniform distribution over [-2, 2.5)\n",
    "noise = np.random.randn(n_train_samples)  # sample from a standard normal distribution\n",
    "y_train = x_train**2 - x_train - 2 + noise\n",
    "\n",
    "### Generate testing data\n",
    "n_test_samples = 20\n",
    "x_test = np.random.uniform(-3, 3, n_test_samples)  # sample from a uniform distribution over [-2, 2.5)\n",
    "noise = np.random.randn(n_test_samples)  # sample from a standard normal distribution\n",
    "y_test = x_test**2 - x_test - 2 + noise\n",
    "\n",
    "### Fit polynomial regression models\n",
    "max_order = 5\n",
    "theta_hats = solve_poly_reg(x_train, y_train, max_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_train, y_train, max_order, n_splits):\n",
    "  \"\"\" Compute MSE for k-fold validation for each order polynomial\n",
    "\n",
    "  Args:\n",
    "    x_train (ndarray): training data input vector of shape (n_samples)\n",
    "    y_train (ndarray): training vector of measurements of shape (n_samples)\n",
    "    max_order (scalar): max order of polynomial fit\n",
    "    n_split (scalar): number of folds for k-fold validation\n",
    "\n",
    "  Return:\n",
    "    ndarray: MSE over splits for each model order, shape (n_splits, max_order + 1)\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  # Initialize the split method\n",
    "  kfold_iterator = KFold(n_splits)\n",
    "\n",
    "  # Initialize np array mse values for all models for each split\n",
    "  mse_all = np.zeros((n_splits, max_order + 1))\n",
    "\n",
    "  for i_split, (train_indices, val_indices) in enumerate(kfold_iterator.split(x_train)):\n",
    "\n",
    "      # Split up the overall training data into cross-validation training and validation sets\n",
    "      x_cv_train = x_train[train_indices]\n",
    "      y_cv_train = y_train[train_indices]\n",
    "      x_cv_val = x_train[val_indices]\n",
    "      y_cv_val = y_train[val_indices]\n",
    "\n",
    "      #############################################################################\n",
    "      ## TODO for students: Fill in missing ... in code below to choose which data\n",
    "      ## to fit to and compute MSE for\n",
    "      # Fill out function and remove\n",
    "      raise NotImplementedError(\"Student exercise: implement cross-validation\")\n",
    "      #############################################################################\n",
    "\n",
    "      # Fit models\n",
    "      theta_hats = ...\n",
    "\n",
    "      # Compute MSE\n",
    "      mse_this_split = ...\n",
    "\n",
    "      mse_all[i_split] = mse_this_split\n",
    "\n",
    "  return mse_all\n",
    "\n",
    "\n",
    "# Cross-validate\n",
    "max_order = 5\n",
    "n_splits = 10\n",
    "mse_all = cross_validate(x_train, y_train, max_order, n_splits)\n",
    "\n",
    "# Visualize\n",
    "plot_cross_validate_MSE(mse_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('blazkowiz')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ee5975616448165ec7473ca23f75162aeb86cbb1e3b29bb11b91e477bc89a19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
